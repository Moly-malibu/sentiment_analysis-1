{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import gps_geometry as gps\n",
    "\n",
    "# Use only the first time\n",
    "conn = sqlite3.connect(\"mydatabase.db\") # or use :memory: to put it in RAM\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMW, daimler, mercedes benz, AMG, audi\n"
     ]
    }
   ],
   "source": [
    "# Read keywords to track from track.csv into variable trackstring\n",
    "\n",
    "import csv\n",
    "with open('track.csv', newline='') as csvfile:\n",
    "    trackreader = csv.reader(csvfile, delimiter=';', quotechar='|')\n",
    "    for row in trackreader:\n",
    "        trackstring = ', '.join(row)\n",
    "        print(','.join(row))\n",
    "\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main body of the streamer class, writes to SQL\n",
    "\n",
    "from twython import TwythonStreamer  \n",
    "import json\n",
    "\n",
    "# Filter out unwanted data\n",
    "def process_tweet(tweet):  \n",
    "    \n",
    "      \n",
    "    tweet_id_str = tweet['id_str']\n",
    "    tweet_text = tweet['text']\n",
    "    tweet_created_at = tweet['created_at']\n",
    "    tweet_user_idstr= tweet['user']['id_str']\n",
    "    tweet_hash_tags = str(tweet['entities']['hashtags'])\n",
    "    \n",
    "     \n",
    "    if(tweet[\"geo\"]!= None):\n",
    "        tweet_geo_coords = tweet[\"geo\"][\"coordinates\"]\n",
    "        tweet_geo_lat =  tweet_geo_coords[0]\n",
    "        tweet_geo_lon =  tweet_geo_coords[1]\n",
    "    else:\n",
    "        tweet_geo_coords = None\n",
    "        tweet_geo_lon = None\n",
    "        tweet_geo_lat = None\n",
    "        \n",
    "    #print(\"geo\",tweet_geo_coords)\n",
    "    #print(\"coordinates\",tweet[\"coordinates\"]) \n",
    "    #print(tweet_hash_tags)\n",
    "    \n",
    "    # User information\n",
    "    tweet_user_id_str = tweet['user']['id_str']\n",
    "    tweet_user_screen_name =  tweet['user']['screen_name']\n",
    "    tweet_user_location = tweet['user']['location']\n",
    "    tweet_user_url =  tweet['user']['url']\n",
    "    tweet_user_description = tweet['user']['description']\n",
    "    tweet_user_created_at = tweet['user']['created_at']\n",
    "    tweet_user_followers_count =tweet['user']['followers_count']\n",
    "    tweet_user_friends_count =tweet['user']['friends_count']\n",
    "    tweet_user_statuses_count =tweet['user']['statuses_count']\n",
    "    tweet_user_time_zone = tweet['user']['time_zone']\n",
    "    \n",
    "    \n",
    "     # Tweet Data: (8 items)\n",
    "    # tweet_log_id, tweet_id_text, tweet_hashtag , tweet_text, created_at,  geo_lat,  geo_long , user_id_text\n",
    "    d = [\"1\", tweet_id_str , tweet_text,tweet_hash_tags,tweet_created_at,tweet_geo_lat,tweet_geo_lon, tweet_user_idstr]\n",
    "    \n",
    "\n",
    "    # User Data: (10 items) \n",
    "    # user_id_text, screen_name, location, url,  description text,\n",
    "    # created_at, followers_count ,  friends_count ,statuses_count , time_zone \n",
    "    d2 = [tweet_user_id_str, tweet_user_screen_name,tweet_user_location,tweet_user_url,\n",
    "          tweet_user_description, tweet_user_created_at,tweet_user_followers_count ,tweet_user_friends_count,\n",
    "         tweet_user_statuses_count,tweet_user_time_zone]\n",
    "    \n",
    "    # Tweet log data: (6 items)\n",
    "    # tweet_log_id, query text, geo_lat, geo_long, radius, timestamp\n",
    "    \n",
    "    return [d, d2]\n",
    "\n",
    "\n",
    "# Create a class that inherits TwythonStreamer\n",
    "class MyStreamer(TwythonStreamer): \n",
    "    \n",
    "    # The class constructor\n",
    "    def __init__(self,app_key, app_secret, oauth_token, oauth_token_secret,queryText='',long='',lat='',Radius=''):\n",
    "        TwythonStreamer.__init__(self,app_key, app_secret, oauth_token, oauth_token_secret)\n",
    "        self.queryText = queryText\n",
    "        self.long = long\n",
    "        self.lat = lat\n",
    "        self.Radius = Radius\n",
    "\n",
    "    # Received data\n",
    "    def on_success(self, data):\n",
    "\n",
    "        # Only collect tweets in English\n",
    "        if data['lang'] == 'en':\n",
    "            print('query info:',self.queryText,self.lat,self.long)\n",
    "            tweet_data = process_tweet(data)\n",
    "            user_id = data['user']['id_str']\n",
    "            time_stamp = data['created_at']\n",
    "            self.save_to_sql(tweet_data, user_id,time_stamp)\n",
    "\n",
    "    # Problem with the API\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n",
    "\n",
    "    # Save each tweet to csv file\n",
    "    def save_to_sql(self, tweet, user_id,time_stamp):\n",
    "        \n",
    "        tweet_log_id = user_id\n",
    "        query_text = self.queryText\n",
    "        query_long = self.long\n",
    "        query_lat = self.lat\n",
    "        query_radius = self.Radius\n",
    "        \n",
    "        # tweet_log_id, query text, geo_lat, geo_long, radius, timestamp\n",
    "        query_data = [tweet_log_id,query_text,query_lat,query_long,query_radius, time_stamp]\n",
    "        \n",
    "        print(query_data )\n",
    "        \n",
    "        \n",
    "        #cursor.execute(\"SELECT count(*) FROM user WHERE user_id_text=?\", (user_id,))\n",
    "        \n",
    "        # Save the User Data, if the user is Unique\n",
    "       # if cursor.fetchone()[0] == 0:\n",
    "       #     cursor.execute(\"INSERT INTO user(user_id_text, screen_name, created_at) VALUES (?,?,?)\", tweet[1])\n",
    "        \n",
    "        # Put a condition for uniqueness\n",
    "        # Save the Tweet Data into the Tweet Data base\n",
    "        cursor.execute(\"INSERT INTO tweet(tweet_log_id,tweet_id_text,tweet_hashtag,tweet_text,created_at,geo_lat, geo_long, user_id_text) VALUES (?,?,?,?,?,?,?,?)\", tweet[0])\n",
    "        \n",
    "        # Save the Tweet log data\n",
    "        cursor.execute(\"INSERT INTO tweet_log(tweet_log_id,query,geo_lat,geo_long,radius,timestamp_at) VALUES (?,?,?,?,?,?)\", query_data)\n",
    "        \n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query info:  52.520008 13.404954\n",
      "['239679516', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:42 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['1629065418', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:50 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['60695557', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:52 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['135784305', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:52 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['941413787848060928', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:54 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['1636462790', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:54 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['2753603212', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:58 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['796322938559623168', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:58 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['2914638532', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:25:58 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['745289688714477569', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:03 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['154622596', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:03 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['965372194934149120', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:03 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['110515822', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:04 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['701696631331287040', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:09 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['67653749', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:09 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['745957342928244737', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:10 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['1012797965940019200', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:14 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['1021784368644349952', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:15 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['932226583200374784', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:16 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['30568449', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:21 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['1017542783618441216', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:22 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['4065206904', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:25 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['232325518', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:29 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['800885463670198272', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:37 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['582671903', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:40 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['4065334934', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:44 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['240509619', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:45 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['82725598', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:47 +0000 2018']\n",
      "query info:  52.520008 13.404954\n",
      "['82725598', '', 52.520008, 13.404954, 50.0, 'Tue Jul 24 22:26:48 +0000 2018']\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: tweet_log.tweet_log_id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c28193639d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                    long=lon,lat=lat,Radius=R)\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Start the stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrackstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeo_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#stream.statuses.filter(track=trackstring)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/twython/streaming/types.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://stream.twitter.com/%s/statuses/filter.json'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m               \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/twython/streaming/api.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, url, method, params)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                       not valid JSON.')\n\u001b[1;32m    153\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_success\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mmessage_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mmessage_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ce0869e09a1c>\u001b[0m in \u001b[0;36mon_success\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtime_stamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_stamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Problem with the API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ce0869e09a1c>\u001b[0m in \u001b[0;36msave_to_sql\u001b[0;34m(self, tweet, user_id, time_stamp)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Save the Tweet log data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INSERT INTO tweet_log(tweet_log_id,query,geo_lat,geo_long,radius,timestamp_at) VALUES (?,?,?,?,?,?)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: UNIQUE constraint failed: tweet_log.tweet_log_id"
     ]
    }
   ],
   "source": [
    "# Get the credentials:\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:  \n",
    "    creds = json.load(file)\n",
    "\n",
    "#geo_locations = '-122.75,36.8,-121.75,37.8,-74,40,-73,41'\n",
    "\n",
    "# Coordinates of berlin\n",
    "lon, lat, R =13.404954, 52.520008, 50.0\n",
    "geo_locations = gps.bounding_square_coordinates(lon,lat,R)\n",
    "\n",
    "# Instantiate from our streaming class\n",
    "stream = MyStreamer(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'],  \n",
    "                    creds['ACCESS_TOKEN_KEY'], creds['ACCESS_TOKEN_SECRET'],\n",
    "                   long=lon,lat=lat,Radius=R)\n",
    "# Start the stream\n",
    "stream.statuses.filter(track=trackstring,locations=geo_locations)  \n",
    "#stream.statuses.filter(track=trackstring)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
